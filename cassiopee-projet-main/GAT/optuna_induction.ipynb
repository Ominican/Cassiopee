{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "Dataframe_Labels = pd.read_csv(\"../../BLCA_DATA/Workspace/labels_str.csv\")\n",
    "Dataframe_link = pd.read_csv(\"../../BLCA_DATA/Workspace/patient_norm.csv\")\n",
    "Dataframe_node = pd.read_csv(\"../../BLCA_DATA/Workspace/node_embedding.csv\")\n",
    "\n",
    "Dataframe_Labels['class_int'], uniques = pd.factorize(Dataframe_Labels['class'])\n",
    "\n",
    "Dataframe_Labels = Dataframe_Labels[~Dataframe_Labels['class_int'].isin([4, 5])]\n",
    "\n",
    "patients_to_keep = Dataframe_Labels['Patient'].unique()\n",
    "\n",
    "Dataframe_link = Dataframe_link[Dataframe_link['Patient'].isin(patients_to_keep)]\n",
    "Dataframe_node = Dataframe_node[Dataframe_node['Patient'].isin(patients_to_keep)]\n",
    "\n",
    "Dataframe_Labels = Dataframe_Labels.reset_index(drop=True)\n",
    "Dataframe_link = Dataframe_link.reset_index(drop=True)\n",
    "Dataframe_node = Dataframe_node.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dict = {0: 'LumP', \n",
    "                1: 'Ba/Sq', \n",
    "                2: 'LumU', \n",
    "                3: 'Stroma-rich'\n",
    "}\n",
    "\n",
    "def count_classes_weights(tensor):\n",
    "    array = tensor.numpy()\n",
    "    classes_tab = { 0: 0, \n",
    "                    1: 0,\n",
    "                    2: 0, \n",
    "                    3: 0\n",
    "    }\n",
    "    for i in array:\n",
    "        classes_tab[i]+=1\n",
    "\n",
    "    mean_nb_classes = 0\n",
    "    for i in classes_tab:\n",
    "        mean_nb_classes += i\n",
    "    mean_nb_classes *= 1/len(classes_tab)\n",
    "    \n",
    "    # normalize the weights\n",
    "    weight_sum = 0\n",
    "    for i in range(len(classes_tab)):\n",
    "        if classes_tab[i] != 0:\n",
    "            weight_sum += mean_nb_classes / classes_tab[i]\n",
    "    alpha = 1 / weight_sum\n",
    "\n",
    "    weight_dict = {}\n",
    "    used_classes = []\n",
    "    for i in range(len(classes_tab)):\n",
    "        if classes_tab[i] != 0:\n",
    "            weight_dict[i] = alpha * (mean_nb_classes / classes_tab[i]) *50\n",
    "            used_classes.append(classes_dict[i])\n",
    "\n",
    "    return used_classes, weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = Dataframe_node.drop(columns=['Patient']).values\n",
    "node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "def get_data(indices, similarity_threshold, Dataframe_link, Dataframe_Labels, num_classes=4):\n",
    "    x_data = node_features[indices]\n",
    "\n",
    "    patient_similarity = cosine_similarity(Dataframe_link.iloc[:, 1:])\n",
    "    similarity_threshold = 0.5  # Exemple de seuil de similarité    \n",
    "\n",
    "    # Calculate the edges and attention ridges for training\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    re_indexed_i = 0\n",
    "    re_indexed_j = 0\n",
    "    for i in indices:\n",
    "        for j in indices:\n",
    "            if i >= j :\n",
    "                break\n",
    "            if patient_similarity[i, j] > similarity_threshold:\n",
    "                edge_index.append([re_indexed_i, re_indexed_j])\n",
    "                edge_attr.append((patient_similarity[i, j] - similarity_threshold)/(1 - similarity_threshold))\n",
    "            re_indexed_j +=1\n",
    "        re_indexed_i +=1\n",
    "        re_indexed_j = 0\n",
    "\n",
    "    node_labels = Dataframe_Labels[\"class_int\"].values\n",
    "    labels = torch.tensor(node_labels[indices], dtype=torch.long)\n",
    "\n",
    "    node_labels = torch.tensor(node_labels, dtype=torch.long)\n",
    "\n",
    "    used_classes, weight_dict = count_classes_weights(node_labels)\n",
    "    Dataframe_Labels['weight'] = [weight_dict[x] for x in Dataframe_Labels['class_int']]\n",
    "    node_weights = torch.tensor(Dataframe_Labels['weight'], dtype=torch.float)\n",
    "\n",
    "    edge_features = torch.tensor(x_data, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.int64).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    node_weights = node_weights[indices]\n",
    "\n",
    "    data = Data(\n",
    "    x=edge_features, \n",
    "    edge_index=edge_index, \n",
    "    edge_attr=edge_attr, \n",
    "    y=labels, \n",
    "    weights=node_weights, \n",
    "    num_classes=num_classes,\n",
    "    num_nodes = len(edge_features),\n",
    "    num_features = edge_features.shape[1],\n",
    "    )\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 1: [372 335 328   8 257 167 119 331  78  81 158 256 317 241 251  75 300  60\n",
      " 365 235   0 190 122 212 227 211 215  69 103 353 254  96 224 194 229 245\n",
      " 341 118 278 255 112 292 139 105 290  40  89   6 150  19  18  23 345 102\n",
      " 203 107 177 273 164 351 109], 61\n",
      "Subset 2: [ 28 276 259 247 124 174 274 293 291 325  63 110 362 225 354 196 334 267\n",
      " 117  26  53  49 147  65 336 342 250 228 175  95  88 181 308 359 263 319\n",
      " 226  42  46 149 214 323  11  84 218  51 191 304 176 363 243 240  32 364\n",
      " 357 310 179 182 208  94 265], 61\n",
      "Subset 3: [153 305 281 148 268 318 219   5  82 123 285 159  38 279  62 151 275 358\n",
      " 197 120  57  35 314  10 173 201 155 376 160 157 186 327 377 204 113 156\n",
      " 348  52 231 210 165  58 246 369  76 303 114 213 269  41  74 125 185 312\n",
      " 343 106 287 136 116   9], 60\n",
      "Subset 4: [ 27   1 193 140 264 356 313 262 183 249  16 371 280 375  20  25 141 368\n",
      "  15  79  12 337 344  30 253   2  85 234 309  61 135  48 128 152 258  77\n",
      " 294 233 311 238  56  93  68  14 322 288 142 260  87 301  21 242 209 361\n",
      " 187  34 161 346 349 326], 60\n",
      "Subset 5: [216 121  50 130 195 277 283 137  80 200 162 163 127  86 339  31  83 295\n",
      "  17  72 350 131 199 284 367 206 340 172 299 126 171 145 143 236 144  47\n",
      " 324 332 282 244 316  98 366 333 296  45 248 170 184 298 261 154   4 266\n",
      "  39 352 374   3 373 132], 60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "similarity_threshold = 0.5\n",
    "test_size = 0.2\n",
    "n_graphs = 5  # Nombre de divisions souhaitées pour train_val_indices\n",
    "\n",
    "# Étape 1: Diviser les indices en ensembles train/validation et test\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    range(len(node_features)), \n",
    "    test_size=test_size, \n",
    "    random_state=1234\n",
    ")\n",
    "\n",
    "# Étape 2: Diviser train_val_indices en n listes d'indices\n",
    "def split_indices(indices, n_graphs):\n",
    "    np.random.shuffle(indices)  # Mélanger les indices pour une division plus aléatoire\n",
    "    return np.array_split(indices, n_graphs)\n",
    "\n",
    "# Appliquer la fonction de division\n",
    "split_train_val_indices = split_indices(train_val_indices, n_graphs)\n",
    "\n",
    "# Affichage des résultats\n",
    "for i, indices in enumerate(split_train_val_indices):\n",
    "    print(f\"Subset {i+1}: {indices}, {len(indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads, data):\n",
    "        super(GATv2, self).__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GATv2Conv(data.num_features, hidden_channels, heads=heads, edge_dim=1))\n",
    "        self.convs.append(GATv2Conv(hidden_channels * heads, data.num_classes, edge_dim=1))\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = F.dropout(x, p=0.6, training=self.training)\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "def weighted_cross_entropy_loss(output, target, weights):\n",
    "    loss = F.cross_entropy(output, target, reduction='none')\n",
    "    weighted_loss = loss * weights[target]\n",
    "    return weighted_loss.mean()\n",
    "\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, data.edge_attr)\n",
    "    loss = weighted_cross_entropy_loss(out[data.train_mask], data.y[data.train_mask], data.weights[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, model\n",
    "\n",
    "def test(model, data, mask):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index, data.edge_attr)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred[mask] == data.y[mask]\n",
    "    acc = int(correct.sum()) / int(mask.sum())\n",
    "    return acc, pred[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 7.093693794570687, 1: 5.8882294896109615, 2: 16.99809645114108, 3: 20.01998026467727}\n",
      "{0: 7.093693794570687, 1: 5.8882294896109615, 2: 16.99809645114108, 3: 20.01998026467727}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83151/2214968373.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_features = torch.tensor(x_data, dtype=torch.float)\n",
      "/tmp/ipykernel_83151/2214968373.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_features = torch.tensor(x_data, dtype=torch.float)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m train_val_data \u001b[38;5;241m=\u001b[39m get_data(train_val_indices, similarity_threshold, Dataframe_link, Dataframe_Labels, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     10\u001b[0m test_data \u001b[38;5;241m=\u001b[39m get_data(test_indices, similarity_threshold, Dataframe_link, Dataframe_Labels, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_val_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_val_data)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_data)\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch_geometric/data/data.py:559\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch_geometric/data/storage.py:96\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "similarity_threshold = 0.5\n",
    "\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    range(len(node_features)), \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_val_data = get_data(train_val_indices, similarity_threshold, Dataframe_link, Dataframe_Labels, num_classes=4)\n",
    "test_data = get_data(test_indices, similarity_threshold, Dataframe_link, Dataframe_Labels, num_classes=4)\n",
    "\n",
    "print(train_val_data)\n",
    "print(test_data)\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to be optimized\n",
    "    hidden_channels = trial.suggest_int('hidden_channels', 15, 45)\n",
    "    heads = trial.suggest_int('heads', 1, 25)\n",
    "    n_graphs = trial.suggest_int('n_graphs', 2, 10)\n",
    "\n",
    "    #define the attributes\n",
    "    data = train_val_data\n",
    "    data_test = test_data\n",
    "    num_epochs = 100\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "    all_test_acc = []\n",
    "\n",
    "    for fold, (_, _) in enumerate(skf.split(data.x, data.y)):\n",
    "\n",
    "        split_train_val_indices = split_indices(data.y, n_graphs)\n",
    "        graph = 1\n",
    "        data_graph_init = get_data(split_train_val_indices[0], similarity_threshold, Dataframe_link, Dataframe_Labels, num_classes=4)\n",
    "\n",
    "        model = GATv2(hidden_channels=hidden_channels, heads=heads, data=data_graph_init)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "        # Appliquer la fonction de division\n",
    "        for node_in_each_graph in split_train_val_indices:\n",
    "            \n",
    "            data_graph = get_data(node_in_each_graph, similarity_threshold, Dataframe_link, Dataframe_Labels, num_classes=4)\n",
    "            # Étape 1: Diviser les indices en ensembles train/validation\n",
    "            train_index, val_index = train_test_split(\n",
    "                range(len(node_in_each_graph)), \n",
    "                test_size=0.2, \n",
    "                random_state=1234\n",
    "            )\n",
    "\n",
    "            # Define masks\n",
    "            data_graph.train_mask = torch.zeros(data_graph.num_nodes, dtype=torch.bool)\n",
    "            data_graph.train_mask[train_index] = True\n",
    "            \n",
    "            data_graph.val_mask = torch.zeros(data_graph.num_nodes, dtype=torch.bool)\n",
    "            data_graph.val_mask[val_index] = True\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in range(1, num_epochs):\n",
    "                loss, model = train(model, data_graph, optimizer)\n",
    "                train_acc, _ = test (model, data_graph, data_graph.train_mask)\n",
    "                val_acc, _ = test(model, data_graph, data_graph.val_mask)\n",
    "                if epoch % 50 == 0:\n",
    "                    print(f'Graph: {graph}, Fold: {fold + 1}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Train_acc {train_acc:.4f}, Val_acc {val_acc:.4f}')\n",
    "            graph += 1\n",
    "        \n",
    "        test_mask = torch.ones(data_test.num_nodes, dtype=torch.bool)\n",
    "        test_acc, _ = test(model, data_test, test_mask)\n",
    "\n",
    "        # Store results\n",
    "        all_test_acc.append(test_acc)\n",
    "\n",
    "    # Calculate mean test accuracy for all folds\n",
    "    mean_test_acc = np.mean(all_test_acc)\n",
    "    return mean_test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 20:36:55,277] A new study created in memory with name: no-name-6878de3f-461e-4cd9-bb17-90385008ef12\n",
      "/tmp/ipykernel_83151/1995053533.py:17: UserWarning: you are shuffling a 'Tensor' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(indices)  # Mélanger les indices pour une division plus aléatoire\n",
      "/tmp/ipykernel_83151/1145424808.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_features = torch.tensor(x_data, dtype=torch.float)\n",
      "/tmp/ipykernel_83151/1145424808.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_features = torch.tensor(x_data, dtype=torch.float)\n",
      "[W 2024-07-14 20:36:55,302] Trial 0 failed with parameters: {'hidden_channels': 30, 'heads': 4, 'n_graphs': 8} because of the following error: IndexError('index 0 is out of bounds for dimension 0 with size 0').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/remik/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_83151/288172153.py\", line 58, in objective\n",
      "    loss, model = train(model, data_graph, optimizer)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_83151/1216009520.py\", line 33, in train\n",
      "    out = model(data.x, data.edge_index, data.edge_attr)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/remik/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/remik/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_83151/1216009520.py\", line 19, in forward\n",
      "    x = conv(x, edge_index, edge_attr)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/remik/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/remik/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/remik/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch_geometric/nn/conv/gatv2_conv.py\", line 283, in forward\n",
      "    edge_index, edge_attr = remove_self_loops(\n",
      "                            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/remik/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch_geometric/utils/loop.py\", line 112, in remove_self_loops\n",
      "    mask = edge_index[0] != edge_index[1]\n",
      "           ~~~~~~~~~~^^^\n",
      "IndexError: index 0 is out of bounds for dimension 0 with size 0\n",
      "[W 2024-07-14 20:36:55,305] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Print the best parameters\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[27], line 58\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs):\n\u001b[0;32m---> 58\u001b[0m     loss, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     train_acc, _ \u001b[38;5;241m=\u001b[39m test (model, data_graph, data_graph\u001b[38;5;241m.\u001b[39mtrain_mask)\n\u001b[1;32m     60\u001b[0m     val_acc, _ \u001b[38;5;241m=\u001b[39m test(model, data_graph, data_graph\u001b[38;5;241m.\u001b[39mval_mask)\n",
      "Cell \u001b[0;32mIn[26], line 33\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, optimizer)\u001b[0m\n\u001b[1;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 33\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m weighted_cross_entropy_loss(out[data\u001b[38;5;241m.\u001b[39mtrain_mask], data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask], data\u001b[38;5;241m.\u001b[39mweights[data\u001b[38;5;241m.\u001b[39mtrain_mask])\n\u001b[1;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[26], line 19\u001b[0m, in \u001b[0;36mGATv2.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(x)\n\u001b[1;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch_geometric/nn/conv/gatv2_conv.py:283\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m         num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(num_nodes, x_r\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 283\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mremove_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m add_self_loops(\n\u001b[1;32m    286\u001b[0m         edge_index, edge_attr, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value,\n\u001b[1;32m    287\u001b[0m         num_nodes\u001b[38;5;241m=\u001b[39mnum_nodes)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n",
      "File \u001b[0;32m~/Documents/Cassiopée/cassiopee-projet/Cass/lib/python3.12/site-packages/torch_geometric/utils/loop.py:112\u001b[0m, in \u001b[0;36mremove_self_loops\u001b[0;34m(edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[1;32m    110\u001b[0m     is_undirected \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mis_undirected\n\u001b[0;32m--> 112\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    113\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m edge_index[:, mask]\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Run the optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
